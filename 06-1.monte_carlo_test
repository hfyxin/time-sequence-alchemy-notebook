{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06-1.monte_carlo_test","provenance":[{"file_id":"1Te6TvWKODfDTYItCheIs0GcZ1_Njp8vx","timestamp":1589811913781},{"file_id":"1PAzSlIrcFSW-eUNDu5AhUC-JAt3u2dT7","timestamp":1589142850370}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FQPr2NeJPTEr"},"source":["Pack previous test in one script, run multiple tests and save the results.\n","\n","Results are saved as a csv file, with the following keys:\n","- id: id of entry\n","- model_name\n","- data_trim: if True, use ts_thres to trim sequence, if False, use ts_thres to filter sequence.\n","- ts_thres: threshold of sample duration\n","- pred_thres: the threshold to classify 1/0, default is 0.5\n","- repeat_id: number of test with the same configuration. Each case is run at least 10 times.\n","- test_acc\n","- test_p\n","- test_r\n","- test_f1\n","\n","Assume the csv file is already created."]},{"cell_type":"code","metadata":{"id":"jcL2tTGTaIIp"},"source":["def get_keys():\n","  '''Don't change.'''\n","  keys = ['id', 'model_name', 'data_trim', 'ts_thres', 'pred_thres', 'repeat_id', 'epochs', 'test_acc', 'test_p', 'test_r', 'test_f1']\n","  return keys"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Cn6-MVTvQ8z"},"source":["# Colab Setup"]},{"cell_type":"code","metadata":{"id":"aMTKISmBg7O4","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1590289126289,"user_tz":240,"elapsed":2181,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"703119af-c732-4a70-c4a9-26dc912a35db"},"source":["# set tensorflow version\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","tf.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.2.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"atNY-SC8hRU9","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1590289151593,"user_tz":240,"elapsed":27475,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"eb209c0b-0b30-444e-85c7-09fcd8bc7761"},"source":["# connect google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m5o7swi1gNJT","colab":{"base_uri":"https://localhost:8080/","height":99},"executionInfo":{"status":"ok","timestamp":1590289155369,"user_tz":240,"elapsed":5094,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"e5f7a758-90a1-4bdb-b64e-439f1278ddae"},"source":["# copy the script file to current folder so it can be imported.\n","import shutil\n","import os\n","original = [\n","  r'/content/drive/My Drive/time_sequence_alchemy/utils/data_prep.py',\n","  r'/content/drive/My Drive/time_sequence_alchemy/utils/model.py',\n","  r'/content/drive/My Drive/time_sequence_alchemy/utils/others.py',\n","  r'/content/drive/My Drive/time_sequence_alchemy/utils/plot.py',\n","  r'/content/drive/My Drive/time_sequence_alchemy/log_embeddings_16_sg.txt',\n","]\n","target = [\n","  r'./utils/data_prep.py',\n","  r'./utils/model.py',\n","  r'./utils/others.py',\n","  r'./utils/plot.py',\n","  r'./log_embeddings_16_sg.txt',\n","]\n","\n","if not os.path.exists('./utils'):\n","  os.makedirs('./utils')\n","\n","for orig, targ in zip(original, target):\n","  shutil.copyfile(orig, targ)\n","  print('Script copied:', targ)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Script copied: ./utils/data_prep.py\n","Script copied: ./utils/model.py\n","Script copied: ./utils/others.py\n","Script copied: ./utils/plot.py\n","Script copied: ./log_embeddings_16_sg.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"my2y2RlbvZRg"},"source":["# data file on Colab\n","data_fn = r'/content/drive/My Drive/time_sequence_alchemy/data/HDFS/Xy_dataset.pkl'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bS6iz42Rvouv"},"source":["from utils.data_prep import tokenize, trim_time_sequence, remove_long_sequence, pad_time_sequence, prepare_dataset_v2\n","from utils.model import TimeChanger_FFT, TimeChangerLstm, TimeChanger, naive_evaluate, load_embeddings\n","from utils.model import ResampleLayer\n","from utils.others import print_train_info_v2, plot_and_save\n","from utils import plot\n","import tensorflow as tf\n","import numpy as np\n","import pickle\n","from time import time\n","from sklearn.metrics import confusion_matrix\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3k4jKgVCWNGS"},"source":["# csv file I/O"]},{"cell_type":"code","metadata":{"id":"NWBMu-KW05Fb","colab":{"base_uri":"https://localhost:8080/","height":48},"executionInfo":{"status":"ok","timestamp":1589992083150,"user_tz":240,"elapsed":750,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"520e3be1-a620-4ff9-cb81-4a4315f08d65"},"source":["# an example\n","eg = {key:[] for key in get_keys()}\n","pd.DataFrame(eg)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_name</th>\n","      <th>data_trim</th>\n","      <th>ts_thres</th>\n","      <th>pred_thres</th>\n","      <th>repeat_id</th>\n","      <th>epochs</th>\n","      <th>test_acc</th>\n","      <th>test_p</th>\n","      <th>test_r</th>\n","      <th>test_f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [id, model_name, data_trim, ts_thres, pred_thres, repeat_id, epochs, test_acc, test_p, test_r, test_f1]\n","Index: []"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Jcv0APmXbK85"},"source":["def append_rows(df, rows):\n","  '''append a row dict to a dataframe.'''\n","\n","  # check id conflict\n","\n","  for idx in rows['id']:\n","    if idx <= df['id'].max():\n","      print('New entry id {} exists in database. New data rejected.'.format(idx))\n","      print(database.loc[database['id']==0])\n","      raise ValueError('New entry id already exists in database. See above for details.')\n","    else: pass\n","\n","  new_df = pd.DataFrame(rows)\n","  return df.append(new_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9_I3U5lc5Aj"},"source":["def read_csv(path):\n","  '''Tailor pd.read_csv() to suit the need. \n","  Note that the index returned from this function does not mean anything.\n","  Use the key 'id' instead. '''\n","\n","  return pd.read_csv(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n1Ix1nEbb4S1"},"source":["def save_csv(df, path):\n","  '''Tailor pd.DataFrame.to_csv() to suit the need. '''\n","\n","  # check against current result.\n","  old_df = read_csv(path)\n","\n","  # save a backup copy\n","  old_df.to_csv(path[:-4]+'_backup'+path[-4:], index=False)\n","\n","  df.to_csv(path, index=False)\n","\n","  print('Database saved.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYYf6H76dZb1","colab":{"base_uri":"https://localhost:8080/","height":413},"executionInfo":{"status":"ok","timestamp":1590291541933,"user_tz":240,"elapsed":866,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"0b6396b4-88fe-417e-a818-81035e20e7ab"},"source":["folder = '/content/drive/My Drive/time_sequence_alchemy/test_result/'\n","fn = 'monte_carlo_results.csv'\n","\n","database = read_csv(folder+fn)\n","database"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_name</th>\n","      <th>data_trim</th>\n","      <th>ts_thres</th>\n","      <th>pred_thres</th>\n","      <th>repeat_id</th>\n","      <th>epochs</th>\n","      <th>test_acc</th>\n","      <th>test_p</th>\n","      <th>test_r</th>\n","      <th>test_f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>Example</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>99.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>26.0</td>\n","      <td>0.999611</td>\n","      <td>1.0</td>\n","      <td>0.999221</td>\n","      <td>0.99961</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>2.0</td>\n","      <td>18.0</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>3.0</td>\n","      <td>19.0</td>\n","      <td>0.999611</td>\n","      <td>1.0</td>\n","      <td>0.999221</td>\n","      <td>0.99961</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>4.0</td>\n","      <td>19.0</td>\n","      <td>0.999611</td>\n","      <td>1.0</td>\n","      <td>0.999221</td>\n","      <td>0.99961</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>236</th>\n","      <td>246.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>6.0</td>\n","      <td>13.0</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","    </tr>\n","    <tr>\n","      <th>237</th>\n","      <td>247.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>7.0</td>\n","      <td>15.0</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","    </tr>\n","    <tr>\n","      <th>238</th>\n","      <td>248.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>8.0</td>\n","      <td>13.0</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","    </tr>\n","    <tr>\n","      <th>239</th>\n","      <td>249.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>9.0</td>\n","      <td>14.0</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","    </tr>\n","    <tr>\n","      <th>240</th>\n","      <td>250.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>10.0</td>\n","      <td>13.0</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>241 rows × 11 columns</p>\n","</div>"],"text/plain":["        id model_name  data_trim  ts_thres  ...  test_acc  test_p    test_r  test_f1\n","0      0.0    Example        0.0     120.0  ...       NaN     NaN       NaN      NaN\n","1      1.0      CNN_1        0.0     120.0  ...  0.999611     1.0  0.999221  0.99961\n","2      2.0      CNN_1        0.0     120.0  ...  1.000000     1.0  1.000000  1.00000\n","3      3.0      CNN_1        0.0     120.0  ...  0.999611     1.0  0.999221  0.99961\n","4      4.0      CNN_1        0.0     120.0  ...  0.999611     1.0  0.999221  0.99961\n","..     ...        ...        ...       ...  ...       ...     ...       ...      ...\n","236  246.0   TS_CNN_1        0.0     120.0  ...  1.000000     1.0  1.000000  1.00000\n","237  247.0   TS_CNN_1        0.0     120.0  ...  1.000000     1.0  1.000000  1.00000\n","238  248.0   TS_CNN_1        0.0     120.0  ...  1.000000     1.0  1.000000  1.00000\n","239  249.0   TS_CNN_1        0.0     120.0  ...  1.000000     1.0  1.000000  1.00000\n","240  250.0   TS_CNN_1        0.0     120.0  ...  1.000000     1.0  1.000000  1.00000\n","\n","[241 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"PdBU55s-cRAa","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1589823082896,"user_tz":240,"elapsed":424,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"5a772503-d45b-4370-a20b-9fea15489038"},"source":["folder = '/content/drive/My Drive/time_sequence_alchemy/test_result/'\n","fn = 'monte_carlo_results.csv'\n","\n","# save_csv(database, folder+fn)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Database saved.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TTP261Gyjczn"},"source":["# Program start"]},{"cell_type":"code","metadata":{"id":"2NSIaHWLjk1B","colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"status":"ok","timestamp":1590293025164,"user_tz":240,"elapsed":866,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"d2ba0e85-f59d-4ae8-9586-398989395621"},"source":["folder = '/content/drive/My Drive/time_sequence_alchemy/test_result/'\n","fn = 'monte_carlo_results.csv'\n","\n","database = read_csv(folder+fn)\n","database.tail()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_name</th>\n","      <th>data_trim</th>\n","      <th>ts_thres</th>\n","      <th>pred_thres</th>\n","      <th>repeat_id</th>\n","      <th>epochs</th>\n","      <th>test_acc</th>\n","      <th>test_p</th>\n","      <th>test_r</th>\n","      <th>test_f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>236</th>\n","      <td>256.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>16.0</td>\n","      <td>12.0</td>\n","      <td>0.985915</td>\n","      <td>1.000000</td>\n","      <td>0.971831</td>\n","      <td>0.985714</td>\n","    </tr>\n","    <tr>\n","      <th>237</th>\n","      <td>257.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>17.0</td>\n","      <td>13.0</td>\n","      <td>0.998826</td>\n","      <td>0.998436</td>\n","      <td>0.999218</td>\n","      <td>0.998827</td>\n","    </tr>\n","    <tr>\n","      <th>238</th>\n","      <td>258.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>18.0</td>\n","      <td>19.0</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","    </tr>\n","    <tr>\n","      <th>239</th>\n","      <td>259.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>19.0</td>\n","      <td>13.0</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","    </tr>\n","    <tr>\n","      <th>240</th>\n","      <td>260.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>20.0</td>\n","      <td>13.0</td>\n","      <td>0.998826</td>\n","      <td>0.998436</td>\n","      <td>0.999218</td>\n","      <td>0.998827</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id model_name  data_trim  ...    test_p    test_r   test_f1\n","236  256.0      CNN_1        0.0  ...  1.000000  0.971831  0.985714\n","237  257.0      CNN_1        0.0  ...  0.998436  0.999218  0.998827\n","238  258.0      CNN_1        0.0  ...  0.998435  0.998435  0.998435\n","239  259.0      CNN_1        0.0  ...  0.998435  0.998435  0.998435\n","240  260.0      CNN_1        0.0  ...  0.998436  0.999218  0.998827\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"markdown","metadata":{"id":"Oc2Zy2U2kBMP"},"source":["**CHANGE THIS.**\n","\n","Set up the model/test configuration."]},{"cell_type":"code","metadata":{"id":"5IgbAPQNjoAi"},"source":["# SET THESE\n","TRIM = False   # trim or filter data (by duration)\n","TS_THRES = 60  # duration threshold \n","PRED_THRES = 0.5 # threshold for classfication\n","\n","# Initialization of the first test\n","this_test = {key:None for key in get_keys()}\n","this_group = {key:[] for key in get_keys()}\n","\n","this_test['id'] = database['id'].max()+1\n","this_test['data_trim'] = TRIM\n","this_test['ts_thres'] = TS_THRES\n","this_test['pred_thres'] = PRED_THRES\n","this_test['repeat_id'] = 11"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wG9yyFaZlGME"},"source":["# The Loop"]},{"cell_type":"markdown","metadata":{"id":"ZOzJtt82mHCq"},"source":["## Load data (the manual loop)\n","\n","No need to change anything."]},{"cell_type":"code","metadata":{"id":"d4MWiJpmlITp","colab":{"base_uri":"https://localhost:8080/","height":116},"executionInfo":{"status":"ok","timestamp":1590293109673,"user_tz":240,"elapsed":64800,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"311bfabf-2a52-4e61-d30f-6dace2db9ef9"},"source":["TS_LIMIT = this_test['ts_thres']  # samples will be trimmed/picked within this limit (sec)\n","TS_TRIM = TS_LIMIT\n","\n","# Load data\n","print('\\nLoading data...', end='')\n","start = time()\n","with open(data_fn,'rb') as f:\n","  X, y = pickle.load(f)\n","print('{:.2f}s\\n'.format(time()-start))\n","\n","# separate value & timestamp\n","print('\\nProcessing data...', end='')\n","start = time()\n","x_seq =  X[:, 0]\n","x_ts = X[:, 1].copy()\n","# y = y[0:5000]\n","del X\n","\n","# tokenization\n","x_tok, tokenizer = tokenize(x_seq)  # 48 tokens\n","vocab_size = len(tokenizer.word_counts)\n","# trim/remove data to a certain time length\n","if this_test['data_trim'] == False:\n","  x_tok, x_ts, y = remove_long_sequence(x_tok, x_ts, y, TS_LIMIT)  # remove sequence that are longer than limit\n","trim_time_sequence(x_tok, x_ts, TS_TRIM)  # trim sequence to limit\n","# front pad data to form matrices.\n","x_tok, x_ts = pad_time_sequence(x_tok, x_ts, \n","    maxlen=250, ts_interval=0.1)\n","\n","print('{:.2f}s\\n'.format(time()-start))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Loading data...25.83s\n","\n","\n","Processing data...38.07s\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EuFuVW4bmEwC","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1590293109675,"user_tz":240,"elapsed":64200,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"a2943caa-01a2-4588-bf8e-5e4b147ecade"},"source":["embeddings, embedding_dims = load_embeddings('./log_embeddings_16_sg.txt')\n","# obtain token - embedding matrix, token zero's embedding is zero.\n","embedding_matrix = np.zeros((vocab_size+1, embedding_dims))\n","\n","for word, i in tokenizer.word_index.items():\n","    embedding_matrix[i] = embeddings[word]\n","\n","print(embedding_matrix.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["vocab_size, embedding_dims: 48 16\n","(49, 16)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9Whst9gr7dHG","colab":{"base_uri":"https://localhost:8080/","height":99},"executionInfo":{"status":"ok","timestamp":1590293110803,"user_tz":240,"elapsed":1116,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"f23b4288-740f-4a97-eb45-98a033d4e622"},"source":["# make dataset\n","test_ratio = 0.2\n","val_ratio = 0.2\n","\n","# balanced dataset (downsampling)\n","_train, _val, _test = prepare_dataset_v2(x_tok, x_ts, y, test_ratio=test_ratio, val_ratio=val_ratio)\n","x_train, ts_train, y_train = _train\n","x_val, ts_val, y_val = _val\n","x_test, ts_test, y_test = _test\n","train_size = len(y_train)\n","val_size = len(y_val)\n","test_size = len(y_test)\n","del _train, _val, _test\n","\n","# checksum\n","print('check these values consistent:', len(y_train)+len(y_val)+len(y_test))\n","print(y_train[0:20], '\\n', y_val[0:20], '\\n', y_test[0:20], '\\n')\n","\n","# make train dataset specifically for manual training\n","batch_size = 64\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, ts_train, y_train)).batch(batch_size).prefetch(2)\n","val_dataset = tf.data.Dataset.from_tensor_slices((x_val, ts_val, y_val)).batch(batch_size).prefetch(2)\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test, ts_test, y_test)).batch(batch_size).prefetch(2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["check these values consistent: 12776\n","[0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 0 0] \n"," [0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0] \n"," [0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0] \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2zR4yNxYnS6K"},"source":["## Initiate models"]},{"cell_type":"code","metadata":{"id":"pSa50Wq5ntdn"},"source":["# CNN model\n","def get_cnn():\n","  model = tf.keras.models.Sequential([\n","    tf.keras.layers.Embedding(\n","      vocab_size+1, embedding_dims,    # +1 because of padding 0\n","      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","      trainable=False, input_length=250),  # input_length=input_length\n","    tf.keras.layers.Conv1D(filters=32, kernel_size=8, strides=3),\n","    tf.keras.layers.GlobalMaxPool1D(),\n","    tf.keras.layers.Dense(units=32, activation='relu'),\n","    tf.keras.layers.Dense(units=32, activation='relu'),\n","    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n","  ])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fqmPbmSnyD-"},"source":["def get_rnn():\n","  model = tf.keras.models.Sequential([\n","    tf.keras.layers.Embedding(\n","      vocab_size+1, embedding_dims,    # +1 because of padding 0\n","      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","      trainable=False, input_length=250),  # input_length=input_length\n","    # tf.keras.layers.LSTM(units=64, return_sequences=True),\n","    tf.keras.layers.LSTM(units=64, return_sequences=False),\n","    tf.keras.layers.Dense(units=32, activation='tanh'),\n","    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n","  ])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2b2-tJvunx-R"},"source":["class TimeChangerCnn(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_matrix):\n","    super().__init__()\n","    \n","    embedding_dims = 16\n","    self.embed = tf.keras.layers.Embedding(\n","      vocab_size+1, embedding_dims,     # +1 because of padding 0\n","      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","      trainable=False, input_length=250)  # input_length=input_length)\n","    max_duration = TS_TRIM # seconds\n","    resolution = 0.1   # seconds\n","    self.resample = ResampleLayer(max_duration, resolution)\n","    self.cnn_model = tf.keras.models.Sequential([\n","      # tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=1),\n","      tf.keras.layers.Conv1D(filters=32, kernel_size=8, strides=3),\n","      # tf.keras.layers.MaxPool1D(pool_size=2),\n","      # tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=1),\n","      tf.keras.layers.GlobalMaxPool1D(),\n","      #tf.keras.layers.MaxPool1D(pool_size=2),\n","      #tf.keras.layers.Flatten(),\n","      tf.keras.layers.Dense(units=32, activation='relu'),\n","      # tf.keras.layers.Dropout(0.2),\n","      tf.keras.layers.Dense(units=32, activation='relu'),\n","      tf.keras.layers.Dense(units=1, activation='sigmoid'),\n","    ])\n","    \n","  #@tf.function\n","  def call(self, data):\n","    in_seq, ts_seq = data\n","    in_seq = self.embed(in_seq)\n","    output = self.resample((in_seq, ts_seq))\n","    output = self.cnn_model(output)\n","    return output\n","\n","def get_tscnn():\n","  model = TimeChangerCnn(vocab_size, embedding_matrix)\n","  model((x_tok[0:2], x_ts[0:2]))\n","  return model\n","# model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKiXayqrnx1D"},"source":["class TimeChangerLstm(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_matrix):\n","    super().__init__()\n","    \n","    embedding_dims = 16\n","    self.embed = tf.keras.layers.Embedding(\n","      vocab_size+1, embedding_dims,     # +1 because of padding 0\n","      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","      trainable=False, input_length=250)  # input_length=input_length)\n","    max_duration = TS_TRIM # seconds\n","    resolution = 0.1   # seconds\n","    self.resample = ResampleLayer(max_duration, resolution)\n","    self.lstm_model = tf.keras.models.Sequential([\n","      # tf.keras.layers.LSTM(units=32, return_sequences=True),\n","      tf.keras.layers.LSTM(units=64, return_sequences=False),\n","      tf.keras.layers.Dense(units=32, activation='tanh'),\n","      tf.keras.layers.Dense(units=1, activation='sigmoid'),\n","    ])\n","\n","  #@tf.function\n","  def call(self, data):\n","    in_seq, ts_seq = data\n","    in_seq = self.embed(in_seq)\n","    output = self.resample((in_seq, ts_seq))\n","    output = self.lstm_model(output)\n","    return output\n","\n","def get_tsrnn():\n","  model = TimeChangerLstm(vocab_size, embedding_matrix)\n","  model((x_tok[0:2], x_ts[0:2]))\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NAGZnDivolaU"},"source":["# sometimes RNN need to run separately\n","'''models = {\n","    'CNN_1': get_cnn,\n","    'RNN_1': get_rnn,\n","    'TS_CNN_1': get_tscnn, \n","#    'TS_RNN_1': get_tsrnn,\n","}'''\n","models = {'TS_RNN_1': get_tsrnn}\n","#models = {'CNN_1': get_cnn}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"azyUgxlYoq8T"},"source":["## Repeat test"]},{"cell_type":"code","metadata":{"id":"0LbBtlyGuYsk"},"source":["def naive_evaluate_v2(model, x, y, faulty_thres=0.5, batch=None):\n","  '''Use sklearn's method, it has better precision.\n","\n","  Parameters:\n","  -----------\n","  batch: only used when x is a tuple. Tailored fro Ts-RNN to prevent\n","  OOM when processing large amount of inputs.\n","  \n","  '''\n","\n","  if batch:\n","    # process data in w/ batch processing\n","    x_tok, x_ts = x\n","    y_prob = [model((x_tok[i*batch:(i+1)*batch], x_ts[i*batch:(i+1)*batch])).numpy() for i in range(int(len(x_tok)/batch)+1)]\n","    y_prob = [arr.squeeze(axis=1) for arr in y_prob]\n","    y_prob = np.concatenate(y_prob)\n","  else:\n","    y_prob = model(x).numpy()\n","\n","  y_pred = y_prob >= faulty_thres\n","  conf_mtx = confusion_matrix(y, y_pred)\n","\n","  # calculate metrics based on confusion matrix\n","  acc = (conf_mtx[0,0] + conf_mtx[1,1]) / conf_mtx.sum()\n","  p = conf_mtx[1,1] / (conf_mtx[0,1] + conf_mtx[1,1])\n","  r = conf_mtx[1,1] / (conf_mtx[1,0] + conf_mtx[1,1])\n","  f1 = 2/(1/p+1/r)\n","\n","  return acc, p, r, f1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1rdTD2t8oqSc","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590294223726,"user_tz":240,"elapsed":1113996,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"cfed239d-a3ea-4369-8877-a55fdbed405d"},"source":["for model_name, get_model in models.items():\n","\n","  this_test['model_name'] = model_name\n","  # repeat_id = database.loc[database['model_name']==model_name, 'repeat_id'].max()\n","\n","  for i in range(1,11):\n","    print('\\nModel {} - #{}...'.format(model_name, i))\n","    # reset model parameters\n","    model = get_model()\n","\n","    # reset metrics\n","    # define metrics, to display during training\n","    train_loss = tf.keras.metrics.Mean()\n","    train_metrics = {\n","        'accuracy': tf.keras.metrics.BinaryAccuracy(),\n","        'precision': tf.keras.metrics.Precision(),\n","        'recall': tf.keras.metrics.Recall(),\n","        }\n","    val_metrics = {\n","        'loss': tf.keras.metrics.Mean(),\n","        'accuracy': tf.keras.metrics.BinaryAccuracy(),\n","        }\n","    # training history and curve\n","    history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}\n","\n","    # define other training parameters\n","    if 'rnn' in model_name.lower():\n","      optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3)   #Adam, SGD\n","    else:\n","      optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)   #Adam, SGD\n","    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","    # start training\n","    print('Start training with {} samples, validate with {} samples'.format(train_size, val_size))\n","    epochs = 1000   # will run 3 hours worst case.\n","    for epoch in range(epochs):\n","      start = time()\n","      \n","      # reset metrics\n","      train_loss.reset_states()\n","      for metric in train_metrics.values():\n","        metric.reset_states()\n","      for metric in val_metrics.values():\n","        metric.reset_states()\n","\n","      for x_batch, ts_batch, y_batch in train_dataset:\n","        with tf.GradientTape() as tape:     # watch_accessed_variables=False\n","          if 'ts' in model_name.lower():\n","            y_pred = model((x_batch, ts_batch))\n","          else:\n","            y_pred = model(x_batch)  # ((x_batch, ts_batch))\n","          y_pred = tf.squeeze(y_pred, 1)   # make it same dimension as y\n","\n","          # Loss value for this minibatch\n","          loss = loss_fn(y_batch, y_pred)\n","          loss += sum(model.losses)  # must have, what does this do?\n","          \n","        grads = tape.gradient(loss, model.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","\n","        # update metrics\n","        train_loss.update_state(loss)\n","        for metric in train_metrics.values():\n","            metric.update_state(y_batch, y_pred)\n","        # print('~', end='')\n","      \n","      # update val metrics\n","      if val_size != 0:\n","        for x_batch, ts_batch, y_batch in val_dataset:\n","          if 'ts' in model_name.lower():\n","            y_val_pred = model((x_batch, ts_batch))\n","          else:\n","            y_val_pred = model(x_batch)\n","          y_val_pred = tf.squeeze(y_val_pred, 1)\n","          loss = loss_fn(y_batch, y_val_pred)\n","          val_metrics['loss'].update_state(loss)\n","          val_metrics['accuracy'].update_state(y_batch, y_val_pred)\n","      \n","      # log \n","      history['train_loss'].append(train_loss.result().numpy())\n","      history['train_acc'].append(train_metrics['accuracy'].result().numpy())\n","      history['val_loss'].append(val_metrics['loss'].result().numpy())\n","      history['val_acc'].append(val_metrics['accuracy'].result().numpy())\n","\n","      if epoch % 10 == 0: print_train_info_v2(epoch, time()-start, history)\n","\n","      # determine early stopping\n","      # sometimes the loss goes up for a short period, do nothing and wait.\n","      # stops only when it's absolutely flat.\n","      \n","      w = 5     # early stopping moving average window\n","      n = 5     # early stopping hesitate epochs\n","      thres = 0.0003        # loss difference threshold, for ts-rnn use 0.0003\n","      acc_thres = 0.1   # absolute loss threshold\n","\n","      if epoch >= n+w+1:\n","        # loss moving average of the last few epochs\n","        loss_MA = [history['train_loss'][i-w:i] for i in range(epoch-n, epoch+1)]\n","        loss_MA = [sum(values) / w for values in loss_MA]\n","        acc_MA = [history['train_acc'][i-w:i] for i in range(epoch-n, epoch+1)]\n","        acc_MA = [sum(values) / w for values in acc_MA]\n","        # for the last n losses, must be going down, and diff < thres\n","        train_stopping = [abs(a-b)<=thres for (a,b) in zip(loss_MA[0:-1], loss_MA[1:])]\n","        if sum(train_stopping) == n and acc_MA[-1] >= acc_thres:\n","          print('Early stopping triggered.')\n","          print_train_info_v2(epoch, time()-start, history)\n","          break\n","\n","    # evaluation metrics (test set)\n","    if 'ts' in model_name.lower():\n","      acc, p, r, f1 = naive_evaluate_v2(model, (x_test, ts_test), y_test, batch=100) #\n","    else:\n","      acc, p, r, f1 = naive_evaluate_v2(model, x_test, y_test)\n","    print('Test result, acc={:.2%}, p={:.2%}, r={:.2%}, f1={:.2%}'.format(acc,p,r,f1))\n","    this_test['test_acc'] = acc\n","    this_test['test_p'] = p\n","    this_test['test_r'] = r\n","    this_test['test_f1'] = f1\n","    this_test['epochs'] = epoch\n","\n","    # logging and clear status\n","    for key, value in this_test.items():\n","      this_group[key].append(value)\n","    this_test['id'] += 1\n","    this_test['repeat_id'] += 1\n","    this_test['test_acc'] = 1\n","    this_test['test_p'] = None\n","    this_test['test_r'] = None\n","    this_test['test_f1'] = None\n","    this_test['epochs'] = None\n","\n","  # end of a model\n","  this_test['repeat_id'] = 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Model TS_RNN_1 - #1...\n","Start training with 8176 samples, validate with 2044 samples\n","epoch 0 - 9s. train_loss: 0.5509 train_acc: 88.89% val_loss: 0.5119 val_acc: 97.90% \n","epoch 10 - 8s. train_loss: 0.5089 train_acc: 98.50% val_loss: 0.5111 val_acc: 97.95% \n","Early stopping triggered.\n","epoch 12 - 8s. train_loss: 0.5089 train_acc: 98.50% val_loss: 0.5111 val_acc: 97.95% \n","Test result, acc=98.51%, p=99.92%, r=97.10%, f1=98.49%\n","\n","Model TS_RNN_1 - #2...\n","Start training with 8176 samples, validate with 2044 samples\n","epoch 0 - 8s. train_loss: 0.5565 train_acc: 86.65% val_loss: 0.5525 val_acc: 87.04% \n","epoch 10 - 9s. train_loss: 0.5480 train_acc: 88.21% val_loss: 0.5527 val_acc: 87.00% \n","Early stopping triggered.\n","epoch 11 - 8s. train_loss: 0.5480 train_acc: 88.21% val_loss: 0.5527 val_acc: 87.00% \n","Test result, acc=88.62%, p=100.00%, r=77.23%, f1=87.15%\n","\n","Model TS_RNN_1 - #3...\n","Start training with 8176 samples, validate with 2044 samples\n","epoch 0 - 8s. train_loss: 0.5537 train_acc: 88.10% val_loss: 0.5526 val_acc: 87.04% \n","epoch 10 - 9s. train_loss: 0.5481 train_acc: 88.18% val_loss: 0.5525 val_acc: 87.04% \n","Early stopping triggered.\n","epoch 11 - 9s. train_loss: 0.5481 train_acc: 88.18% val_loss: 0.5525 val_acc: 87.04% \n","Test result, acc=88.62%, p=100.00%, r=77.23%, f1=87.15%\n","\n","Model TS_RNN_1 - #4...\n","Start training with 8176 samples, validate with 2044 samples\n","epoch 0 - 9s. train_loss: 0.5560 train_acc: 87.24% val_loss: 0.5526 val_acc: 87.04% \n","epoch 10 - 8s. train_loss: 0.5481 train_acc: 88.18% val_loss: 0.5525 val_acc: 87.04% \n","Early stopping triggered.\n","epoch 11 - 8s. train_loss: 0.5481 train_acc: 88.18% val_loss: 0.5525 val_acc: 87.04% \n","Test result, acc=88.62%, p=100.00%, r=77.23%, f1=87.15%\n","\n","Model TS_RNN_1 - #5...\n","Start training with 8176 samples, validate with 2044 samples\n","epoch 0 - 8s. train_loss: 0.5541 train_acc: 87.41% val_loss: 0.5525 val_acc: 87.04% \n","epoch 10 - 8s. train_loss: 0.5481 train_acc: 88.18% val_loss: 0.5525 val_acc: 87.04% \n","Early stopping triggered.\n","epoch 11 - 8s. train_loss: 0.5481 train_acc: 88.18% val_loss: 0.5525 val_acc: 87.04% \n","Test result, acc=88.62%, p=100.00%, r=77.23%, f1=87.15%\n","\n","Model TS_RNN_1 - #6...\n","Start training with 8176 samples, validate with 2044 samples\n","epoch 0 - 8s. train_loss: 0.5244 train_acc: 95.61% val_loss: 0.5113 val_acc: 97.90% \n","epoch 10 - 8s. train_loss: 0.5481 train_acc: 88.18% val_loss: 0.5525 val_acc: 87.04% \n","Early stopping triggered.\n","epoch 14 - 8s. train_loss: 0.5481 train_acc: 88.18% val_loss: 0.5525 val_acc: 87.04% \n","Test result, acc=88.58%, p=99.90%, r=77.23%, f1=87.11%\n","\n","Model TS_RNN_1 - #7...\n","Start training with 8176 samples, validate with 2044 samples\n","epoch 0 - 8s. train_loss: 0.5556 train_acc: 87.40% val_loss: 0.5526 val_acc: 87.04% \n","epoch 10 - 9s. train_loss: 0.5090 train_acc: 98.49% val_loss: 0.5114 val_acc: 97.85% \n","Early stopping triggered.\n","epoch 16 - 9s. train_loss: 0.5089 train_acc: 98.50% val_loss: 0.5111 val_acc: 97.95% \n","Test result, acc=98.59%, p=100.00%, r=97.18%, f1=98.57%\n","\n","Model TS_RNN_1 - #8...\n","Start training with 8176 samples, validate with 2044 samples\n","epoch 0 - 8s. train_loss: 0.5562 train_acc: 87.17% val_loss: 0.5526 val_acc: 87.04% \n","epoch 10 - 8s. train_loss: 0.5481 train_acc: 88.18% val_loss: 0.5525 val_acc: 87.04% \n","Early stopping triggered.\n","epoch 11 - 9s. train_loss: 0.5481 train_acc: 88.18% val_loss: 0.5525 val_acc: 87.04% \n","Test result, acc=88.62%, p=100.00%, r=77.23%, f1=87.15%\n","\n","Model TS_RNN_1 - #9...\n","Start training with 8176 samples, validate with 2044 samples\n","epoch 0 - 8s. train_loss: 0.5253 train_acc: 95.41% val_loss: 0.5113 val_acc: 97.90% \n","epoch 10 - 8s. train_loss: 0.5089 train_acc: 98.50% val_loss: 0.5111 val_acc: 97.95% \n","Early stopping triggered.\n","epoch 11 - 9s. train_loss: 0.5089 train_acc: 98.50% val_loss: 0.5111 val_acc: 97.95% \n","Test result, acc=98.51%, p=99.92%, r=97.10%, f1=98.49%\n","\n","Model TS_RNN_1 - #10...\n","Start training with 8176 samples, validate with 2044 samples\n","epoch 0 - 8s. train_loss: 0.5545 train_acc: 87.39% val_loss: 0.5525 val_acc: 87.04% \n","epoch 10 - 9s. train_loss: 0.5088 train_acc: 98.55% val_loss: 0.5106 val_acc: 98.10% \n","Early stopping triggered.\n","epoch 12 - 9s. train_loss: 0.5088 train_acc: 98.56% val_loss: 0.5106 val_acc: 98.10% \n","Test result, acc=98.71%, p=99.84%, r=97.57%, f1=98.69%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R4n_K36x0Swc"},"source":["# Save database"]},{"cell_type":"code","metadata":{"id":"qXnxuuty0VcR","colab":{"base_uri":"https://localhost:8080/","height":659},"executionInfo":{"status":"ok","timestamp":1590292137461,"user_tz":240,"elapsed":459,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"e8fe1d80-155f-4da7-895c-d2dc02dc5468"},"source":["database = append_rows(database, this_group)\n","database.tail(20)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_name</th>\n","      <th>data_trim</th>\n","      <th>ts_thres</th>\n","      <th>pred_thres</th>\n","      <th>repeat_id</th>\n","      <th>epochs</th>\n","      <th>test_acc</th>\n","      <th>test_p</th>\n","      <th>test_r</th>\n","      <th>test_f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>231</th>\n","      <td>241.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>14.0</td>\n","      <td>0.998832</td>\n","      <td>1.000000</td>\n","      <td>0.997664</td>\n","      <td>0.998830</td>\n","    </tr>\n","    <tr>\n","      <th>232</th>\n","      <td>242.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>2.0</td>\n","      <td>12.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>233</th>\n","      <td>243.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>3.0</td>\n","      <td>14.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>234</th>\n","      <td>244.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>4.0</td>\n","      <td>13.0</td>\n","      <td>0.999221</td>\n","      <td>1.000000</td>\n","      <td>0.998442</td>\n","      <td>0.999221</td>\n","    </tr>\n","    <tr>\n","      <th>235</th>\n","      <td>245.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>5.0</td>\n","      <td>12.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>236</th>\n","      <td>246.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>6.0</td>\n","      <td>13.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>237</th>\n","      <td>247.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>7.0</td>\n","      <td>15.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>238</th>\n","      <td>248.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>8.0</td>\n","      <td>13.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>239</th>\n","      <td>249.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>9.0</td>\n","      <td>14.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>240</th>\n","      <td>250.0</td>\n","      <td>TS_CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>10.0</td>\n","      <td>13.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>251.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>11.0</td>\n","      <td>14.0</td>\n","      <td>0.998826</td>\n","      <td>0.998436</td>\n","      <td>0.999218</td>\n","      <td>0.998827</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>252.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>12.0</td>\n","      <td>18.0</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>253.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>13.0</td>\n","      <td>12.0</td>\n","      <td>0.999218</td>\n","      <td>0.998437</td>\n","      <td>1.000000</td>\n","      <td>0.999218</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>254.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>14.0</td>\n","      <td>13.0</td>\n","      <td>0.998826</td>\n","      <td>0.999217</td>\n","      <td>0.998435</td>\n","      <td>0.998826</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>255.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>15.0</td>\n","      <td>19.0</td>\n","      <td>0.999218</td>\n","      <td>0.998437</td>\n","      <td>1.000000</td>\n","      <td>0.999218</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>256.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>16.0</td>\n","      <td>12.0</td>\n","      <td>0.985915</td>\n","      <td>1.000000</td>\n","      <td>0.971831</td>\n","      <td>0.985714</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>257.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>17.0</td>\n","      <td>13.0</td>\n","      <td>0.998826</td>\n","      <td>0.998436</td>\n","      <td>0.999218</td>\n","      <td>0.998827</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>258.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>18.0</td>\n","      <td>19.0</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>259.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>19.0</td>\n","      <td>13.0</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>260.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>20.0</td>\n","      <td>13.0</td>\n","      <td>0.998826</td>\n","      <td>0.998436</td>\n","      <td>0.999218</td>\n","      <td>0.998827</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id model_name  data_trim  ...    test_p    test_r   test_f1\n","231  241.0   TS_CNN_1        0.0  ...  1.000000  0.997664  0.998830\n","232  242.0   TS_CNN_1        0.0  ...  1.000000  1.000000  1.000000\n","233  243.0   TS_CNN_1        0.0  ...  1.000000  1.000000  1.000000\n","234  244.0   TS_CNN_1        0.0  ...  1.000000  0.998442  0.999221\n","235  245.0   TS_CNN_1        0.0  ...  1.000000  1.000000  1.000000\n","236  246.0   TS_CNN_1        0.0  ...  1.000000  1.000000  1.000000\n","237  247.0   TS_CNN_1        0.0  ...  1.000000  1.000000  1.000000\n","238  248.0   TS_CNN_1        0.0  ...  1.000000  1.000000  1.000000\n","239  249.0   TS_CNN_1        0.0  ...  1.000000  1.000000  1.000000\n","240  250.0   TS_CNN_1        0.0  ...  1.000000  1.000000  1.000000\n","0    251.0      CNN_1        0.0  ...  0.998436  0.999218  0.998827\n","1    252.0      CNN_1        0.0  ...  0.998435  0.998435  0.998435\n","2    253.0      CNN_1        0.0  ...  0.998437  1.000000  0.999218\n","3    254.0      CNN_1        0.0  ...  0.999217  0.998435  0.998826\n","4    255.0      CNN_1        0.0  ...  0.998437  1.000000  0.999218\n","5    256.0      CNN_1        0.0  ...  1.000000  0.971831  0.985714\n","6    257.0      CNN_1        0.0  ...  0.998436  0.999218  0.998827\n","7    258.0      CNN_1        0.0  ...  0.998435  0.998435  0.998435\n","8    259.0      CNN_1        0.0  ...  0.998435  0.998435  0.998435\n","9    260.0      CNN_1        0.0  ...  0.998436  0.999218  0.998827\n","\n","[20 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"6KdrZxPZ0dnU","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1590292620860,"user_tz":240,"elapsed":3281,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"5d176204-0aba-4b52-e332-e4432beda66e"},"source":["folder = '/content/drive/My Drive/time_sequence_alchemy/test_result/'\n","fn = 'monte_carlo_results.csv'\n","\n","save_csv(database, folder+fn)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Database saved.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-F-SAkxH0S3l"},"source":["database = db"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlW_6_dV0lgE","colab":{"base_uri":"https://localhost:8080/","height":413},"executionInfo":{"status":"ok","timestamp":1590292537101,"user_tz":240,"elapsed":831,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"b0f7dac8-f68f-436e-8f03-2b6bc692e00d"},"source":["database"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_name</th>\n","      <th>data_trim</th>\n","      <th>ts_thres</th>\n","      <th>pred_thres</th>\n","      <th>repeat_id</th>\n","      <th>epochs</th>\n","      <th>test_acc</th>\n","      <th>test_p</th>\n","      <th>test_r</th>\n","      <th>test_f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>Example</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>99.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>26.0</td>\n","      <td>0.999611</td>\n","      <td>1.000000</td>\n","      <td>0.999221</td>\n","      <td>0.999610</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>2.0</td>\n","      <td>18.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>3.0</td>\n","      <td>19.0</td>\n","      <td>0.999611</td>\n","      <td>1.000000</td>\n","      <td>0.999221</td>\n","      <td>0.999610</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>0.5</td>\n","      <td>4.0</td>\n","      <td>19.0</td>\n","      <td>0.999611</td>\n","      <td>1.000000</td>\n","      <td>0.999221</td>\n","      <td>0.999610</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>256.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>16.0</td>\n","      <td>12.0</td>\n","      <td>0.985915</td>\n","      <td>1.000000</td>\n","      <td>0.971831</td>\n","      <td>0.985714</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>257.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>17.0</td>\n","      <td>13.0</td>\n","      <td>0.998826</td>\n","      <td>0.998436</td>\n","      <td>0.999218</td>\n","      <td>0.998827</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>258.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>18.0</td>\n","      <td>19.0</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>259.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>19.0</td>\n","      <td>13.0</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","      <td>0.998435</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>260.0</td>\n","      <td>CNN_1</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>0.5</td>\n","      <td>20.0</td>\n","      <td>13.0</td>\n","      <td>0.998826</td>\n","      <td>0.998436</td>\n","      <td>0.999218</td>\n","      <td>0.998827</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>251 rows × 11 columns</p>\n","</div>"],"text/plain":["       id model_name  data_trim  ...    test_p    test_r   test_f1\n","0     0.0    Example        0.0  ...       NaN       NaN       NaN\n","1     1.0      CNN_1        0.0  ...  1.000000  0.999221  0.999610\n","2     2.0      CNN_1        0.0  ...  1.000000  1.000000  1.000000\n","3     3.0      CNN_1        0.0  ...  1.000000  0.999221  0.999610\n","4     4.0      CNN_1        0.0  ...  1.000000  0.999221  0.999610\n","..    ...        ...        ...  ...       ...       ...       ...\n","5   256.0      CNN_1        0.0  ...  1.000000  0.971831  0.985714\n","6   257.0      CNN_1        0.0  ...  0.998436  0.999218  0.998827\n","7   258.0      CNN_1        0.0  ...  0.998435  0.998435  0.998435\n","8   259.0      CNN_1        0.0  ...  0.998435  0.998435  0.998435\n","9   260.0      CNN_1        0.0  ...  0.998436  0.999218  0.998827\n","\n","[251 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"AJhyYZ6L0cGN","colab":{"base_uri":"https://localhost:8080/","height":301},"executionInfo":{"status":"error","timestamp":1590292531557,"user_tz":240,"elapsed":1030,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"4a9cc740-e723-4876-a804-ddccade311b0"},"source":["database.loc[1:10,:]"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-67-bd13d77a4714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1287\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1912\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1913\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1795\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m         indexer = labels.slice_indexer(\n\u001b[0;32m-> 1797\u001b[0;31m             \u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m         )\n\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_indexer\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   4710\u001b[0m         \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4711\u001b[0m         \"\"\"\n\u001b[0;32m-> 4712\u001b[0;31m         \u001b[0mstart_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4714\u001b[0m         \u001b[0;31m# return a slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_locs\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   4923\u001b[0m         \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4924\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4925\u001b[0;31m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_slice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4927\u001b[0m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   4856\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4857\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4858\u001b[0;31m                     \u001b[0;34mf\"Cannot get {side} slice bound for non-unique \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4859\u001b[0m                     \u001b[0;34mf\"label: {repr(original_label)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4860\u001b[0m                 )\n","\u001b[0;31mKeyError\u001b[0m: 'Cannot get left slice bound for non-unique label: 1'"]}]},{"cell_type":"code","metadata":{"id":"XrdMLenfwXVJ"},"source":["db = pd.concat([database.loc[0:30,:], database.loc[41:,:]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6n5F4OBR0CU6","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1590292602630,"user_tz":240,"elapsed":1064,"user":{"displayName":"Yixin Huangfu","photoUrl":"","userId":"05723928591492295374"}},"outputId":"933a647f-30e0-4dba-f7d3-f38957911a9d"},"source":["db.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(241, 11)"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"id":"XObtGloHz5u7"},"source":[""],"execution_count":null,"outputs":[]}]}