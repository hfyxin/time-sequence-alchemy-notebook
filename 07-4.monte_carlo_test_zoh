{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"07-4.monte_carlo_test_zoh","provenance":[{"file_id":"1Te6TvWKODfDTYItCheIs0GcZ1_Njp8vx","timestamp":1589811913781},{"file_id":"1PAzSlIrcFSW-eUNDu5AhUC-JAt3u2dT7","timestamp":1589142850370}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FQPr2NeJPTEr"},"source":["Pack previous test in one script, run multiple tests and save the results.\n","\n","**IMPORTANT FOR COLAB:** longer sequence settings lead to long execution time, which may exceed colab limit. You can run mutiple tests separately to avoid this. Change the repeat_id and the numer of for loops indicated in the code.\n","\n","Results are saved as a csv file, with the following keys:\n","- id: id of entry\n","- model_name\n","- data_trim: if True, use ts_thres to trim sequence, if False, use ts_thres to filter sequence.\n","- ts_thres: threshold of sample duration\n","- pred_thres: the threshold to classify 1/0, default is 0.5\n","- repeat_id: number of test with the same configuration. Each case is run at least 10 times.\n","- test_acc\n","- test_p\n","- test_r\n","- test_f1\n","\n","Assume the csv file is already created."]},{"cell_type":"code","metadata":{"id":"jcL2tTGTaIIp"},"source":["def get_keys():\n","  '''Don't change.'''\n","  keys = ['id', 'model_name', 'data_trim', 'ts_thres', 'pred_thres', 'repeat_id', 'epochs', 'test_acc', 'test_p', 'test_r', 'test_f1']\n","  return keys"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Cn6-MVTvQ8z"},"source":["# Colab Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"aMTKISmBg7O4","executionInfo":{"status":"ok","timestamp":1628623384379,"user_tz":240,"elapsed":2101,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"1ca61664-a0f1-4d76-8519-1aaf5fd687c0"},"source":["# set tensorflow version\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","tf.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.5.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"atNY-SC8hRU9","executionInfo":{"status":"ok","timestamp":1628623401064,"user_tz":240,"elapsed":16688,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"4bf31271-18a3-4ec5-8009-66845c8e84ac"},"source":["# connect google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5o7swi1gNJT","executionInfo":{"status":"ok","timestamp":1628623404395,"user_tz":240,"elapsed":3335,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"eaa69b9d-82ee-45a7-a389-351d4a6a15b1"},"source":["# copy the script file to current folder so it can be imported.\n","import shutil\n","import os\n","original = [\n","  r'/content/drive/My Drive/time_sequence_alchemy/utils/data_prep.py',\n","  r'/content/drive/My Drive/time_sequence_alchemy/utils/model.py',\n","  r'/content/drive/My Drive/time_sequence_alchemy/utils/others.py',\n","  r'/content/drive/My Drive/time_sequence_alchemy/utils/plot.py',\n","  r'/content/drive/My Drive/time_sequence_alchemy/log_embeddings_16_sg.txt',\n","]\n","target = [\n","  r'./utils/data_prep.py',\n","  r'./utils/model.py',\n","  r'./utils/others.py',\n","  r'./utils/plot.py',\n","  r'./log_embeddings_16_sg.txt',\n","]\n","\n","if not os.path.exists('./utils'):\n","  os.makedirs('./utils')\n","\n","for orig, targ in zip(original, target):\n","  shutil.copyfile(orig, targ)\n","  print('Script copied:', targ)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Script copied: ./utils/data_prep.py\n","Script copied: ./utils/model.py\n","Script copied: ./utils/others.py\n","Script copied: ./utils/plot.py\n","Script copied: ./log_embeddings_16_sg.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"my2y2RlbvZRg"},"source":["# data file on Colab\n","data_fn = r'/content/drive/My Drive/time_sequence_alchemy/data/HDFS/Xy_dataset.pkl'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bS6iz42Rvouv"},"source":["from utils.data_prep import tokenize, trim_time_sequence, remove_long_sequence, pad_time_sequence\n","from utils.data_prep import prepare_dataset_v3, oversample_dataset\n","from utils.model import TimeChanger_FFT, TimeChangerLstm, TimeChanger, naive_evaluate, load_embeddings\n","from utils.model import ResampleLayer\n","from utils.others import print_train_info_v2, plot_and_save\n","from utils import plot\n","import tensorflow as tf\n","import numpy as np\n","import pickle\n","from time import time\n","from sklearn.metrics import confusion_matrix\n","from matplotlib import pyplot as plt\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3k4jKgVCWNGS"},"source":["# csv file I/O"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49},"id":"NWBMu-KW05Fb","executionInfo":{"status":"ok","timestamp":1628623404927,"user_tz":240,"elapsed":10,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"4fe813c8-8a80-4f14-c210-d9ad9f145aa0"},"source":["# an example\n","eg = {key:[] for key in get_keys()}\n","pd.DataFrame(eg)\n","\n","# DON'T RUN if file already exists!!\n","# pd.DataFrame(eg).to_csv(folder+fn, index=False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_name</th>\n","      <th>data_trim</th>\n","      <th>ts_thres</th>\n","      <th>pred_thres</th>\n","      <th>repeat_id</th>\n","      <th>epochs</th>\n","      <th>test_acc</th>\n","      <th>test_p</th>\n","      <th>test_r</th>\n","      <th>test_f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [id, model_name, data_trim, ts_thres, pred_thres, repeat_id, epochs, test_acc, test_p, test_r, test_f1]\n","Index: []"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Jcv0APmXbK85"},"source":["def append_rows(df, rows):\n","  '''append a row dict to a dataframe.'''\n","\n","  # check id conflict\n","\n","  for idx in rows['id']:\n","    if idx <= df['id'].max():\n","      print('New entry id {} exists in database. New data rejected.'.format(idx))\n","      print(database.loc[database['id']==0])\n","      raise ValueError('New entry id already exists in database. See above for details.')\n","    else: pass\n","\n","  new_df = pd.DataFrame(rows)\n","  return df.append(new_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9_I3U5lc5Aj"},"source":["def read_csv(path):\n","  '''Tailor pd.read_csv() to suit the need. \n","  Note that the index returned from this function does not mean anything.\n","  Use the key 'id' instead. '''\n","\n","  return pd.read_csv(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQiDXEsoLD7p"},"source":["def save_csv(df, path):\n","  '''Tailor pd.DataFrame.to_csv() to suit the need. '''\n","\n","  # check against current result.\n","  old_df = read_csv(path)\n","\n","  # save a backup copy\n","  old_df.to_csv(path[:-4]+'_backup'+path[-4:], index=False)\n","\n","  df.to_csv(path, index=False)\n","\n","  print('Database saved.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"wYYf6H76dZb1","executionInfo":{"status":"ok","timestamp":1628623405944,"user_tz":240,"elapsed":480,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"0e531fd0-8660-4fce-d19c-f2f1973108f0"},"source":["folder = '/content/drive/My Drive/time_sequence_alchemy/test_result/'\n","fn = 'monte_carlo_results_imbalance.csv'\n","\n","database = read_csv(folder+fn)\n","database"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_name</th>\n","      <th>data_trim</th>\n","      <th>ts_thres</th>\n","      <th>pred_thres</th>\n","      <th>repeat_id</th>\n","      <th>epochs</th>\n","      <th>test_acc</th>\n","      <th>test_p</th>\n","      <th>test_r</th>\n","      <th>test_f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>CNN_1</td>\n","      <td>False</td>\n","      <td>120</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0.998123</td>\n","      <td>0.999199</td>\n","      <td>0.971184</td>\n","      <td>0.984992</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>CNN_1</td>\n","      <td>False</td>\n","      <td>120</td>\n","      <td>0.5</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0.999605</td>\n","      <td>0.994574</td>\n","      <td>0.999221</td>\n","      <td>0.996892</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>CNN_1</td>\n","      <td>False</td>\n","      <td>120</td>\n","      <td>0.5</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.999506</td>\n","      <td>0.993798</td>\n","      <td>0.998442</td>\n","      <td>0.996115</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>CNN_1</td>\n","      <td>False</td>\n","      <td>120</td>\n","      <td>0.5</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0.999556</td>\n","      <td>0.994569</td>\n","      <td>0.998442</td>\n","      <td>0.996502</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>CNN_1</td>\n","      <td>False</td>\n","      <td>120</td>\n","      <td>0.5</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0.999407</td>\n","      <td>0.992260</td>\n","      <td>0.998442</td>\n","      <td>0.995342</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>331</th>\n","      <td>342</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0.996839</td>\n","      <td>0.987918</td>\n","      <td>0.939824</td>\n","      <td>0.963271</td>\n","    </tr>\n","    <tr>\n","      <th>332</th>\n","      <td>343</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.990368</td>\n","      <td>0.919448</td>\n","      <td>0.856660</td>\n","      <td>0.886944</td>\n","    </tr>\n","    <tr>\n","      <th>333</th>\n","      <td>344</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0.993439</td>\n","      <td>0.995279</td>\n","      <td>0.855308</td>\n","      <td>0.920000</td>\n","    </tr>\n","    <tr>\n","      <th>334</th>\n","      <td>345</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0.993231</td>\n","      <td>0.978593</td>\n","      <td>0.865450</td>\n","      <td>0.918550</td>\n","    </tr>\n","    <tr>\n","      <th>335</th>\n","      <td>346</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>0.991769</td>\n","      <td>0.892368</td>\n","      <td>0.924949</td>\n","      <td>0.908367</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>336 rows × 11 columns</p>\n","</div>"],"text/plain":["      id  model_name  data_trim  ...    test_p    test_r   test_f1\n","0      1       CNN_1      False  ...  0.999199  0.971184  0.984992\n","1      2       CNN_1      False  ...  0.994574  0.999221  0.996892\n","2      3       CNN_1      False  ...  0.993798  0.998442  0.996115\n","3      4       CNN_1      False  ...  0.994569  0.998442  0.996502\n","4      5       CNN_1      False  ...  0.992260  0.998442  0.995342\n","..   ...         ...        ...  ...       ...       ...       ...\n","331  342  TS_RNN_ZOH      False  ...  0.987918  0.939824  0.963271\n","332  343  TS_RNN_ZOH      False  ...  0.919448  0.856660  0.886944\n","333  344  TS_RNN_ZOH      False  ...  0.995279  0.855308  0.920000\n","334  345  TS_RNN_ZOH      False  ...  0.978593  0.865450  0.918550\n","335  346  TS_RNN_ZOH      False  ...  0.892368  0.924949  0.908367\n","\n","[336 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"PdBU55s-cRAa"},"source":["folder = '/content/drive/My Drive/time_sequence_alchemy/test_result/'\n","fn = 'monte_carlo_results_imbalance.csv'\n","\n","# save_csv(database, folder+fn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TTP261Gyjczn"},"source":["# Program start"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"2NSIaHWLjk1B","executionInfo":{"status":"ok","timestamp":1628623405946,"user_tz":240,"elapsed":9,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"e9a384ae-acc1-46a6-a8f1-c6e2fc1d1123"},"source":["folder = '/content/drive/My Drive/time_sequence_alchemy/test_result/'\n","fn = 'monte_carlo_results_imbalance.csv'\n","\n","database = read_csv(folder+fn)\n","database.tail(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_name</th>\n","      <th>data_trim</th>\n","      <th>ts_thres</th>\n","      <th>pred_thres</th>\n","      <th>repeat_id</th>\n","      <th>epochs</th>\n","      <th>test_acc</th>\n","      <th>test_p</th>\n","      <th>test_r</th>\n","      <th>test_f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>326</th>\n","      <td>337</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>0.991605</td>\n","      <td>0.891838</td>\n","      <td>0.951168</td>\n","      <td>0.920548</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>338</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>0.990628</td>\n","      <td>0.869398</td>\n","      <td>0.961076</td>\n","      <td>0.912941</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>339</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>0.990918</td>\n","      <td>0.925953</td>\n","      <td>0.893843</td>\n","      <td>0.909615</td>\n","    </tr>\n","    <tr>\n","      <th>329</th>\n","      <td>340</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>0.996924</td>\n","      <td>0.983261</td>\n","      <td>0.956122</td>\n","      <td>0.969501</td>\n","    </tr>\n","    <tr>\n","      <th>330</th>\n","      <td>341</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0.994960</td>\n","      <td>0.994713</td>\n","      <td>0.890467</td>\n","      <td>0.939707</td>\n","    </tr>\n","    <tr>\n","      <th>331</th>\n","      <td>342</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0.996839</td>\n","      <td>0.987918</td>\n","      <td>0.939824</td>\n","      <td>0.963271</td>\n","    </tr>\n","    <tr>\n","      <th>332</th>\n","      <td>343</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.990368</td>\n","      <td>0.919448</td>\n","      <td>0.856660</td>\n","      <td>0.886944</td>\n","    </tr>\n","    <tr>\n","      <th>333</th>\n","      <td>344</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0.993439</td>\n","      <td>0.995279</td>\n","      <td>0.855308</td>\n","      <td>0.920000</td>\n","    </tr>\n","    <tr>\n","      <th>334</th>\n","      <td>345</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0.993231</td>\n","      <td>0.978593</td>\n","      <td>0.865450</td>\n","      <td>0.918550</td>\n","    </tr>\n","    <tr>\n","      <th>335</th>\n","      <td>346</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>0.991769</td>\n","      <td>0.892368</td>\n","      <td>0.924949</td>\n","      <td>0.908367</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  model_name  data_trim  ...    test_p    test_r   test_f1\n","326  337  TS_RNN_ZOH      False  ...  0.891838  0.951168  0.920548\n","327  338  TS_RNN_ZOH      False  ...  0.869398  0.961076  0.912941\n","328  339  TS_RNN_ZOH      False  ...  0.925953  0.893843  0.909615\n","329  340  TS_RNN_ZOH      False  ...  0.983261  0.956122  0.969501\n","330  341  TS_RNN_ZOH      False  ...  0.994713  0.890467  0.939707\n","331  342  TS_RNN_ZOH      False  ...  0.987918  0.939824  0.963271\n","332  343  TS_RNN_ZOH      False  ...  0.919448  0.856660  0.886944\n","333  344  TS_RNN_ZOH      False  ...  0.995279  0.855308  0.920000\n","334  345  TS_RNN_ZOH      False  ...  0.978593  0.865450  0.918550\n","335  346  TS_RNN_ZOH      False  ...  0.892368  0.924949  0.908367\n","\n","[10 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"Oc2Zy2U2kBMP"},"source":["## Model Config (change this)\n","\n","Set up the model/test configuration."]},{"cell_type":"code","metadata":{"id":"5IgbAPQNjoAi"},"source":["# SET THESE\n","TRIM = False   # trim or filter data (by duration)\n","TS_THRES = 1920  # duration threshold    <============= CHANGE THIS\n","PRED_THRES = 0.5 # threshold for classfication\n","\n","# Initialization of the first test\n","this_test = {key:None for key in get_keys()}\n","this_group = {key:[] for key in get_keys()}\n","\n","this_test['id'] = database['id'].max()+1\n","this_test['data_trim'] = TRIM\n","this_test['ts_thres'] = TS_THRES\n","this_test['pred_thres'] = PRED_THRES\n","this_test['repeat_id'] = 7   # The idx of this test, 1-10 <=========== AND THIS"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wG9yyFaZlGME"},"source":["# The Loop"]},{"cell_type":"markdown","metadata":{"id":"ZOzJtt82mHCq"},"source":["## Load data\n","\n","No need to change anything."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4MWiJpmlITp","executionInfo":{"status":"ok","timestamp":1628623502224,"user_tz":240,"elapsed":96285,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"89f9e3cf-ea29-4cb3-afa5-978fac8ae49e"},"source":["TS_LIMIT = this_test['ts_thres']  # samples will be trimmed/picked within this limit (sec)\n","TS_TRIM = TS_LIMIT\n","\n","# Load data\n","print('\\nLoading data...', end='')\n","start = time()\n","with open(data_fn,'rb') as f:\n","  X, y = pickle.load(f)\n","print('{:.2f}s'.format(time()-start), end='\\t')\n","print('{:d} samples'.format(len(y)))\n","\n","# separate value & timestamp\n","print('\\nProcessing data...', end='')\n","start = time()\n","x_seq =  X[:, 0]\n","x_ts = X[:, 1].copy()\n","# y = y[0:5000]\n","del X\n","\n","# tokenization\n","x_tok, tokenizer = tokenize(x_seq)  # 48 tokens\n","vocab_size = len(tokenizer.word_counts)\n","# trim/remove data to a certain time length\n","if this_test['data_trim'] == False:\n","  x_tok, x_ts, y = remove_long_sequence(x_tok, x_ts, y, TS_LIMIT)  # remove sequence that are longer than limit\n","trim_time_sequence(x_tok, x_ts, TS_TRIM)  # trim sequence to limit\n","# front pad data to form matrices.\n","x_tok, x_ts = pad_time_sequence(x_tok, x_ts, \n","    maxlen=250, ts_interval=0.1)\n","\n","print('{:.2f}s'.format(time()-start), end='\\t')\n","print('{:d} samples, {:d} samples with label=1.'.format(len(y), sum(y)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Loading data...35.03s\t575061 samples\n","\n","Processing data...61.08s\t167661 samples, 7393 samples with label=1.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EuFuVW4bmEwC","executionInfo":{"status":"ok","timestamp":1628623502224,"user_tz":240,"elapsed":6,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"b1623f28-bc5d-42fb-ef98-d3cb3a5dc44f"},"source":["embeddings, embedding_dims = load_embeddings('./log_embeddings_16_sg.txt')\n","# obtain token - embedding matrix, token zero's embedding is zero.\n","embedding_matrix = np.zeros((vocab_size+1, embedding_dims))\n","\n","for word, i in tokenizer.word_index.items():\n","    embedding_matrix[i] = embeddings[word]\n","\n","print(embedding_matrix.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["vocab_size, embedding_dims: 48 16\n","(49, 16)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Whst9gr7dHG","executionInfo":{"status":"ok","timestamp":1628623505961,"user_tz":240,"elapsed":3740,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"c1a46dbb-2dc0-4ff1-d898-eb7cfad833d0"},"source":["# make dataset\n","test_ratio = 0.2\n","val_ratio = 0.2\n","\n","# Dataset split\n","_train, _val, _test = prepare_dataset_v3(x_tok, x_ts, y, test_ratio=test_ratio, val_ratio=val_ratio)\n","x_train, ts_train, y_train = _train\n","x_val, ts_val, y_val = _val\n","x_test, ts_test, y_test = _test\n","train_size, val_size, test_size = [len(y_train), len(y_val), len(y_test)]\n","# del _train, _val, _test\n","\n","print('Available data samples:', len(y_train)+len(y_val)+len(y_test), end=', \\t')\n","print('train:{}, val:{}, test:{}\\n'.format(train_size, val_size, test_size))\n","\n","# balance training dataset (oversampling)\n","x_train, ts_train, y_train = oversample_dataset(x_train, ts_train, y_train)\n","train_size = len(x_train)\n","\n","# checksum\n","print('After balancing the training dataset,', end='\\t')\n","print('train:{}, val:{}, test:{}\\n'.format(train_size, val_size, test_size))\n","\n","print('Check the first 20 labels of each dataset are consistent:')\n","print(y_train[0:20], '\\n', y_val[0:20], '\\n', y_test[0:20], '\\n')\n","\n","# make tensorflow style dataset for manual training\n","batch_size = 64   # set smaller if TS-RNN is OOM\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, ts_train, y_train)).batch(batch_size).prefetch(2)\n","val_dataset = tf.data.Dataset.from_tensor_slices((x_val, ts_val, y_val)).batch(batch_size).prefetch(2)\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test, ts_test, y_test)).batch(batch_size).prefetch(2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Available data samples: 167661, \ttrain:107302, val:26826, test:33533\n","\n","After balancing the training dataset,\ttrain:205142, val:26826, test:33533\n","\n","Check the first 20 labels of each dataset are consistent:\n","[1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0] \n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] \n"," [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0] \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2zR4yNxYnS6K"},"source":["## Initiate models"]},{"cell_type":"code","metadata":{"id":"pSa50Wq5ntdn"},"source":["# CNN model\n","def get_cnn():\n","  model = tf.keras.models.Sequential([\n","    tf.keras.layers.Embedding(\n","      vocab_size+1, embedding_dims,    # +1 because of padding 0\n","      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","      trainable=False, input_length=250),  # input_length=input_length\n","    tf.keras.layers.Conv1D(filters=32, kernel_size=8, strides=3),\n","    tf.keras.layers.GlobalMaxPool1D(),\n","    tf.keras.layers.Dense(units=32, activation='relu'),\n","    tf.keras.layers.Dense(units=32, activation='relu'),\n","    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n","  ])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fqmPbmSnyD-"},"source":["def get_rnn():\n","  model = tf.keras.models.Sequential([\n","    tf.keras.layers.Embedding(\n","      vocab_size+1, embedding_dims,    # +1 because of padding 0\n","      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","      trainable=False, input_length=250),  # input_length=input_length\n","    # tf.keras.layers.LSTM(units=64, return_sequences=True),\n","    tf.keras.layers.LSTM(units=64, return_sequences=False),\n","    tf.keras.layers.Dense(units=32, activation='tanh'),\n","    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n","  ])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2b2-tJvunx-R"},"source":["class TimeChangerCnn(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_matrix):\n","    super().__init__()\n","    \n","    embedding_dims = 16\n","    self.embed = tf.keras.layers.Embedding(\n","      vocab_size+1, embedding_dims,     # +1 because of padding 0\n","      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","      trainable=False, input_length=250)  # input_length=input_length)\n","    max_duration = TS_TRIM # seconds\n","    resolution = 0.1   # seconds\n","    self.resample = ResampleLayer(max_duration, resolution)\n","    self.cnn_model = tf.keras.models.Sequential([\n","      # tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=1),\n","      tf.keras.layers.Conv1D(filters=32, kernel_size=8, strides=3),\n","      # tf.keras.layers.MaxPool1D(pool_size=2),\n","      # tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=1),\n","      tf.keras.layers.GlobalMaxPool1D(),\n","      #tf.keras.layers.MaxPool1D(pool_size=2),\n","      #tf.keras.layers.Flatten(),\n","      tf.keras.layers.Dense(units=32, activation='relu'),\n","      # tf.keras.layers.Dropout(0.2),\n","      tf.keras.layers.Dense(units=32, activation='relu'),\n","      tf.keras.layers.Dense(units=1, activation='sigmoid'),\n","    ])\n","    \n","  #@tf.function\n","  def call(self, data):\n","    in_seq, ts_seq = data\n","    in_seq = self.embed(in_seq)\n","    output = self.resample((in_seq, ts_seq))\n","    output = self.cnn_model(output)\n","    return output\n","\n","def get_tscnn():\n","  model = TimeChangerCnn(vocab_size, embedding_matrix)\n","  model((x_tok[0:2], x_ts[0:2]))\n","  return model\n","# model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKiXayqrnx1D"},"source":["class TimeChangerLstm(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_matrix):\n","    super().__init__()\n","    \n","    embedding_dims = 16\n","    self.embed = tf.keras.layers.Embedding(\n","      vocab_size+1, embedding_dims,     # +1 because of padding 0\n","      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","      trainable=False, input_length=250)  # input_length=input_length)\n","    max_duration = TS_TRIM # seconds\n","    resolution = 0.1   # seconds\n","    self.resample = ResampleLayer(max_duration, resolution)\n","    self.lstm_model = tf.keras.models.Sequential([\n","      # tf.keras.layers.LSTM(units=32, return_sequences=True),\n","      tf.keras.layers.LSTM(units=64, return_sequences=False),\n","      tf.keras.layers.Dense(units=32, activation='tanh'),\n","      tf.keras.layers.Dense(units=1, activation='sigmoid'),\n","    ])\n","\n","  #@tf.function\n","  def call(self, data):\n","    in_seq, ts_seq = data\n","    in_seq = self.embed(in_seq)\n","    output = self.resample((in_seq, ts_seq))\n","    output = self.lstm_model(output)\n","    return output\n","\n","def get_tsrnn():\n","  model = TimeChangerLstm(vocab_size, embedding_matrix)\n","  model((x_tok[0:2], x_ts[0:2]))\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FoZQTCWDSm-r"},"source":["class TimeChangerCnnZOH(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_matrix):\n","    super().__init__()\n","    \n","    embedding_dims = 16\n","    self.embed = tf.keras.layers.Embedding(\n","      vocab_size+1, embedding_dims,     # +1 because of padding 0\n","      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","      trainable=False, input_length=250)  # input_length=input_length)\n","    max_duration = TS_TRIM # seconds\n","    resolution = 0.1   # seconds\n","    self.resample = ResampleLayer(max_duration, resolution, method='zoh')\n","    self.cnn_model = tf.keras.models.Sequential([\n","      # tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=1),\n","      tf.keras.layers.Conv1D(filters=32, kernel_size=8, strides=3),\n","      # tf.keras.layers.MaxPool1D(pool_size=2),\n","      # tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=1),\n","      tf.keras.layers.GlobalMaxPool1D(),\n","      #tf.keras.layers.MaxPool1D(pool_size=2),\n","      #tf.keras.layers.Flatten(),\n","      tf.keras.layers.Dense(units=32, activation='relu'),\n","      # tf.keras.layers.Dropout(0.2),\n","      tf.keras.layers.Dense(units=32, activation='relu'),\n","      tf.keras.layers.Dense(units=1, activation='sigmoid'),\n","    ])\n","    \n","  #@tf.function\n","  def call(self, data):\n","    in_seq, ts_seq = data\n","    in_seq = self.embed(in_seq)\n","    output = self.resample((in_seq, ts_seq))\n","    output = self.cnn_model(output)\n","    return output\n","\n","def get_tscnn_zoh():\n","  model = TimeChangerCnnZOH(vocab_size, embedding_matrix)\n","  model((x_tok[0:2], x_ts[0:2]))\n","  return model\n","# model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XscZ7A1XUaSv"},"source":["class TimeChangerLstmZOH(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_matrix):\n","    super().__init__()\n","    \n","    embedding_dims = 16\n","    self.embed = tf.keras.layers.Embedding(\n","      vocab_size+1, embedding_dims,     # +1 because of padding 0\n","      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","      trainable=False, input_length=250)  # input_length=input_length)\n","    max_duration = TS_TRIM # seconds\n","    resolution = 0.1   # seconds\n","    self.resample = ResampleLayer(max_duration, resolution, method='zoh')\n","    self.lstm_model = tf.keras.models.Sequential([\n","      # tf.keras.layers.LSTM(units=32, return_sequences=True),\n","      tf.keras.layers.LSTM(units=64, return_sequences=False),\n","      tf.keras.layers.Dense(units=32, activation='tanh'),\n","      tf.keras.layers.Dense(units=1, activation='sigmoid'),\n","    ])\n","\n","  #@tf.function\n","  def call(self, data):\n","    in_seq, ts_seq = data\n","    in_seq = self.embed(in_seq)\n","    output = self.resample((in_seq, ts_seq))\n","    output = self.lstm_model(output)\n","    return output\n","\n","def get_tsrnn_zoh():\n","  model = TimeChangerLstmZOH(vocab_size, embedding_matrix)\n","  model((x_tok[0:2], x_ts[0:2]))\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nsdSRtv7nzJt"},"source":["### Models for This Run"]},{"cell_type":"code","metadata":{"id":"NAGZnDivolaU"},"source":["# sometimes RNN need to run separately\n","models = {\n","#    'CNN_1': get_cnn,\n","#    'RNN_1': get_rnn,\n","#    'TS_CNN_1': get_tscnn, \n","#    'TS_RNN_1': get_tsrnn,\n","#    'TS_CNN_ZOH': get_tscnn_zoh,\n","    'TS_RNN_ZOH': get_tsrnn_zoh,\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"azyUgxlYoq8T"},"source":["## Repeat test"]},{"cell_type":"code","metadata":{"id":"0LbBtlyGuYsk"},"source":["def naive_evaluate_v2(model, x, y, faulty_thres=0.5, batch=None):\n","  '''Use sklearn's method, it's more precise.\n","\n","  Parameters:\n","  -----------\n","  batch: number of samples to run each batch, use this when having OOS issues.\n","  \n","  '''\n","\n","  if batch:\n","    # process data in w/ batch processing\n","    if type(x) == tuple:\n","      x_tok, x_ts = x\n","      y_prob = [model((x_tok[i*batch:(i+1)*batch], x_ts[i*batch:(i+1)*batch])).numpy() for i in range(int(len(x_tok)/batch)+1)]\n","    else:\n","      x_tok = x\n","      y_prob = [model(x_tok[i*batch:(i+1)*batch]).numpy() for i in range(int(len(x_tok)/batch)+1)]\n","\n","    y_prob = [arr.squeeze(axis=1) for arr in y_prob]\n","    y_prob = np.concatenate(y_prob)\n","  else:\n","    y_prob = model(x).numpy()\n","\n","  y_pred = y_prob >= faulty_thres\n","  conf_mtx = confusion_matrix(y, y_pred)\n","\n","  # calculate metrics based on confusion matrix\n","  acc = (conf_mtx[0,0] + conf_mtx[1,1]) / conf_mtx.sum()\n","  p = conf_mtx[1,1] / (conf_mtx[0,1] + conf_mtx[1,1])\n","  r = conf_mtx[1,1] / (conf_mtx[1,0] + conf_mtx[1,1])\n","  f1 = 2/(1/p+1/r)\n","\n","  return y_prob, conf_mtx, acc, p, r, f1\n","# naive_evaluate_v2(model, (x_test, ts_test), y_test, batch=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1rdTD2t8oqSc","executionInfo":{"status":"ok","timestamp":1628682391013,"user_tz":240,"elapsed":17486284,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"8087d37a-ccb8-4573-b76b-be03cf2485b5"},"source":["for model_name, get_model in models.items():\n","\n","  this_test['model_name'] = model_name\n","  # repeat_id = database.loc[database['model_name']==model_name, 'repeat_id'].max()\n","\n","  for i in range(1,5):             # <=============== CHANGE THIS FOR PARTIAL TEST\n","    print('\\nModel {} - #{}...'.format(model_name, i))\n","    # reset model parameters\n","    model = get_model()\n","\n","    # reset metrics\n","    # define metrics, to display during training\n","    train_loss = tf.keras.metrics.Mean()\n","    train_metrics = {\n","        'accuracy': tf.keras.metrics.BinaryAccuracy(),\n","        'precision': tf.keras.metrics.Precision(),\n","        'recall': tf.keras.metrics.Recall(),\n","        }\n","    val_metrics = {\n","        'loss': tf.keras.metrics.Mean(),\n","        'accuracy': tf.keras.metrics.BinaryAccuracy(),\n","        }\n","    # training history and curve\n","    history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}\n","\n","    # define other training parameters\n","    if 'rnn' in model_name.lower():\n","      optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3)   #Adam, SGD\n","    else:\n","      optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)   #Adam, SGD\n","    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","    # start training\n","    print('Start training with {} samples, validate with {} samples'.format(train_size, val_size))\n","    epochs = 5   # will run 3 hours worst case.\n","    for epoch in range(epochs):\n","      start = time()\n","      \n","      # reset metrics\n","      train_loss.reset_states()\n","      for metric in train_metrics.values():\n","        metric.reset_states()\n","      for metric in val_metrics.values():\n","        metric.reset_states()\n","\n","      for x_batch, ts_batch, y_batch in train_dataset:\n","        with tf.GradientTape() as tape:     # watch_accessed_variables=False\n","          if 'ts' in model_name.lower():\n","            y_pred = model((x_batch, ts_batch))\n","          else:\n","            y_pred = model(x_batch)  # ((x_batch, ts_batch))\n","          y_pred = tf.squeeze(y_pred, 1)   # make it same dimension as y\n","\n","          # Loss value for this minibatch\n","          loss = loss_fn(y_batch, y_pred)\n","          loss += sum(model.losses)  # must have, what does this do?\n","          \n","        grads = tape.gradient(loss, model.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","\n","        # update metrics\n","        train_loss.update_state(loss)\n","        for metric in train_metrics.values():\n","            metric.update_state(y_batch, y_pred)\n","        # print('~', end='')\n","      \n","      # update val metrics\n","      if val_size != 0:\n","        for x_batch, ts_batch, y_batch in val_dataset:\n","          if 'ts' in model_name.lower():\n","            y_val_pred = model((x_batch, ts_batch))\n","          else:\n","            y_val_pred = model(x_batch)\n","          y_val_pred = tf.squeeze(y_val_pred, 1)\n","          loss = loss_fn(y_batch, y_val_pred)\n","          val_metrics['loss'].update_state(loss)\n","          val_metrics['accuracy'].update_state(y_batch, y_val_pred)\n","      \n","      # log \n","      history['train_loss'].append(train_loss.result().numpy())\n","      history['train_acc'].append(train_metrics['accuracy'].result().numpy())\n","      history['val_loss'].append(val_metrics['loss'].result().numpy())\n","      history['val_acc'].append(val_metrics['accuracy'].result().numpy())\n","\n","      if epoch % 10 == 0: print_train_info_v2(epoch, time()-start, history)\n","\n","      # determine early stopping\n","      # sometimes the loss goes up for a short period, do nothing and wait.\n","      # stops only when it's absolutely flat.\n","      \n","      w = 5     # early stopping moving average window\n","      n = 5     # early stopping hesitate epochs\n","      thres = 0.0003        # loss difference threshold, for ts-rnn use 0.0003\n","      acc_thres = 0.1   # absolute loss threshold\n","\n","      if epoch >= n+w+1:\n","        # loss moving average of the last few epochs\n","        loss_MA = [history['train_loss'][i-w:i] for i in range(epoch-n, epoch+1)]\n","        loss_MA = [sum(values) / w for values in loss_MA]\n","        acc_MA = [history['train_acc'][i-w:i] for i in range(epoch-n, epoch+1)]\n","        acc_MA = [sum(values) / w for values in acc_MA]\n","        # for the last n losses, must be going down, and diff < thres\n","        train_stopping = [abs(a-b)<=thres for (a,b) in zip(loss_MA[0:-1], loss_MA[1:])]\n","        if sum(train_stopping) == n and acc_MA[-1] >= acc_thres:\n","          print('Early stopping triggered.')\n","          print_train_info_v2(epoch, time()-start, history)\n","          break\n","\n","    # evaluation metrics (test set)\n","    if 'ts' in model_name.lower():\n","      _, __, acc, p, r, f1 = naive_evaluate_v2(model, (x_test, ts_test), y_test, batch=256) #\n","    else:\n","      _, __, acc, p, r, f1 = naive_evaluate_v2(model, x_test, y_test, batch=256)\n","    print('Test result, acc={:.2%}, p={:.2%}, r={:.2%}, f1={:.2%}'.format(acc,p,r,f1))\n","    this_test['test_acc'] = acc\n","    this_test['test_p'] = p\n","    this_test['test_r'] = r\n","    this_test['test_f1'] = f1\n","    this_test['epochs'] = epoch\n","\n","    # logging and clear status\n","    for key, value in this_test.items():\n","      this_group[key].append(value)\n","    this_test['id'] += 1\n","    this_test['repeat_id'] += 1\n","    this_test['test_acc'] = 1\n","    this_test['test_p'] = None\n","    this_test['test_r'] = None\n","    this_test['test_f1'] = None\n","    this_test['epochs'] = None\n","\n","  # end of a model\n","  this_test['repeat_id'] = 1"],"execution_count":26,"outputs":[{"output_type":"stream","text":["\n","Model TS_RNN_ZOH - #1...\n","Start training with 205142 samples, validate with 26826 samples\n","epoch 0 - 3006s. train_loss: 0.5309 train_acc: 92.84% val_loss: 0.6784 val_acc: 99.46% \n","Test result, acc=99.49%, p=99.47%, r=88.98%, f1=93.93%\n","\n","Model TS_RNN_ZOH - #2...\n","Start training with 205142 samples, validate with 26826 samples\n","epoch 0 - 2921s. train_loss: 0.5220 train_acc: 95.38% val_loss: 0.6779 val_acc: 99.62% \n","Test result, acc=99.59%, p=97.86%, r=92.77%, f1=95.24%\n","\n","Model TS_RNN_ZOH - #3...\n","Start training with 205142 samples, validate with 26826 samples\n","epoch 0 - 2913s. train_loss: 0.5288 train_acc: 93.63% val_loss: 0.6784 val_acc: 99.46% \n","Test result, acc=99.49%, p=99.47%, r=88.98%, f1=93.93%\n","\n","Model TS_RNN_ZOH - #4...\n","Start training with 205142 samples, validate with 26826 samples\n","epoch 0 - 2926s. train_loss: 0.5342 train_acc: 92.02% val_loss: 0.6810 val_acc: 98.98% \n","Test result, acc=99.04%, p=91.94%, r=85.67%, f1=88.69%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R4n_K36x0Swc"},"source":["# Save database"]},{"cell_type":"code","metadata":{"id":"qXnxuuty0VcR","colab":{"base_uri":"https://localhost:8080/","height":669},"executionInfo":{"status":"ok","timestamp":1628682391014,"user_tz":240,"elapsed":4,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"2fd17940-c39f-415d-f9b0-b6a6d80f4b2a"},"source":["database = append_rows(database, this_group)\n","database.tail(20)"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_name</th>\n","      <th>data_trim</th>\n","      <th>ts_thres</th>\n","      <th>pred_thres</th>\n","      <th>repeat_id</th>\n","      <th>epochs</th>\n","      <th>test_acc</th>\n","      <th>test_p</th>\n","      <th>test_r</th>\n","      <th>test_f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>320</th>\n","      <td>331</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0.994247</td>\n","      <td>0.997619</td>\n","      <td>0.889597</td>\n","      <td>0.940516</td>\n","    </tr>\n","    <tr>\n","      <th>321</th>\n","      <td>332</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0.994391</td>\n","      <td>0.997627</td>\n","      <td>0.892427</td>\n","      <td>0.942099</td>\n","    </tr>\n","    <tr>\n","      <th>322</th>\n","      <td>333</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.995622</td>\n","      <td>0.996923</td>\n","      <td>0.917197</td>\n","      <td>0.955400</td>\n","    </tr>\n","    <tr>\n","      <th>323</th>\n","      <td>334</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0.994319</td>\n","      <td>0.997623</td>\n","      <td>0.891012</td>\n","      <td>0.941308</td>\n","    </tr>\n","    <tr>\n","      <th>324</th>\n","      <td>335</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0.996382</td>\n","      <td>0.983076</td>\n","      <td>0.945506</td>\n","      <td>0.963925</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>336</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>0.995622</td>\n","      <td>0.996923</td>\n","      <td>0.917197</td>\n","      <td>0.955400</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>337</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>0.991605</td>\n","      <td>0.891838</td>\n","      <td>0.951168</td>\n","      <td>0.920548</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>338</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>0.990628</td>\n","      <td>0.869398</td>\n","      <td>0.961076</td>\n","      <td>0.912941</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>339</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>0.990918</td>\n","      <td>0.925953</td>\n","      <td>0.893843</td>\n","      <td>0.909615</td>\n","    </tr>\n","    <tr>\n","      <th>329</th>\n","      <td>340</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>960</td>\n","      <td>0.5</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>0.996924</td>\n","      <td>0.983261</td>\n","      <td>0.956122</td>\n","      <td>0.969501</td>\n","    </tr>\n","    <tr>\n","      <th>330</th>\n","      <td>341</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0.994960</td>\n","      <td>0.994713</td>\n","      <td>0.890467</td>\n","      <td>0.939707</td>\n","    </tr>\n","    <tr>\n","      <th>331</th>\n","      <td>342</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0.996839</td>\n","      <td>0.987918</td>\n","      <td>0.939824</td>\n","      <td>0.963271</td>\n","    </tr>\n","    <tr>\n","      <th>332</th>\n","      <td>343</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.990368</td>\n","      <td>0.919448</td>\n","      <td>0.856660</td>\n","      <td>0.886944</td>\n","    </tr>\n","    <tr>\n","      <th>333</th>\n","      <td>344</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0.993439</td>\n","      <td>0.995279</td>\n","      <td>0.855308</td>\n","      <td>0.920000</td>\n","    </tr>\n","    <tr>\n","      <th>334</th>\n","      <td>345</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0.993231</td>\n","      <td>0.978593</td>\n","      <td>0.865450</td>\n","      <td>0.918550</td>\n","    </tr>\n","    <tr>\n","      <th>335</th>\n","      <td>346</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>0.991769</td>\n","      <td>0.892368</td>\n","      <td>0.924949</td>\n","      <td>0.908367</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>347</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>0.994930</td>\n","      <td>0.994709</td>\n","      <td>0.889790</td>\n","      <td>0.939329</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>348</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>0.995914</td>\n","      <td>0.978602</td>\n","      <td>0.927654</td>\n","      <td>0.952447</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>349</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>0.994930</td>\n","      <td>0.994709</td>\n","      <td>0.889790</td>\n","      <td>0.939329</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>350</td>\n","      <td>TS_RNN_ZOH</td>\n","      <td>False</td>\n","      <td>1920</td>\n","      <td>0.5</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>0.990368</td>\n","      <td>0.919448</td>\n","      <td>0.856660</td>\n","      <td>0.886944</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  model_name  data_trim  ...    test_p    test_r   test_f1\n","320  331  TS_RNN_ZOH      False  ...  0.997619  0.889597  0.940516\n","321  332  TS_RNN_ZOH      False  ...  0.997627  0.892427  0.942099\n","322  333  TS_RNN_ZOH      False  ...  0.996923  0.917197  0.955400\n","323  334  TS_RNN_ZOH      False  ...  0.997623  0.891012  0.941308\n","324  335  TS_RNN_ZOH      False  ...  0.983076  0.945506  0.963925\n","325  336  TS_RNN_ZOH      False  ...  0.996923  0.917197  0.955400\n","326  337  TS_RNN_ZOH      False  ...  0.891838  0.951168  0.920548\n","327  338  TS_RNN_ZOH      False  ...  0.869398  0.961076  0.912941\n","328  339  TS_RNN_ZOH      False  ...  0.925953  0.893843  0.909615\n","329  340  TS_RNN_ZOH      False  ...  0.983261  0.956122  0.969501\n","330  341  TS_RNN_ZOH      False  ...  0.994713  0.890467  0.939707\n","331  342  TS_RNN_ZOH      False  ...  0.987918  0.939824  0.963271\n","332  343  TS_RNN_ZOH      False  ...  0.919448  0.856660  0.886944\n","333  344  TS_RNN_ZOH      False  ...  0.995279  0.855308  0.920000\n","334  345  TS_RNN_ZOH      False  ...  0.978593  0.865450  0.918550\n","335  346  TS_RNN_ZOH      False  ...  0.892368  0.924949  0.908367\n","0    347  TS_RNN_ZOH      False  ...  0.994709  0.889790  0.939329\n","1    348  TS_RNN_ZOH      False  ...  0.978602  0.927654  0.952447\n","2    349  TS_RNN_ZOH      False  ...  0.994709  0.889790  0.939329\n","3    350  TS_RNN_ZOH      False  ...  0.919448  0.856660  0.886944\n","\n","[20 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"6KdrZxPZ0dnU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628682391216,"user_tz":240,"elapsed":204,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}},"outputId":"66c6ea17-cd75-42f7-ebfb-02fefe4542d9"},"source":["folder = '/content/drive/My Drive/time_sequence_alchemy/test_result/'\n","fn = 'monte_carlo_results_imbalance.csv'\n","\n","save_csv(database, folder+fn)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Database saved.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QAi6GoUKGYR3","executionInfo":{"status":"ok","timestamp":1628682391217,"user_tz":240,"elapsed":2,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}}},"source":["#database[database.model_name=='RNN_1']\n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCPKYgHlmt_Z","executionInfo":{"status":"ok","timestamp":1628682391217,"user_tz":240,"elapsed":1,"user":{"displayName":"Elliot Huangfu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6KcYPj7fA4ECUcVIp-Q6rfyLzWLd5UWxAB0wjJeM=s64","userId":"08403768673266368377"}}},"source":[""],"execution_count":29,"outputs":[]}]}